import os
import json
import io
import re
import numpy as np
import streamlit as st
import pandas as pd
import gspread
import textwrap
from oauth2client.service_account import ServiceAccountCredentials
from gspread.exceptions import SpreadsheetNotFound, WorksheetNotFound

# ==== Page / UX ====  (–î–û–õ–ñ–ù–û –±—ã—Ç—å —Å–∞–º—ã–º –ø–µ—Ä–≤—ã–º –≤—ã–∑–æ–≤–æ–º Streamlit)
st.set_page_config(
    page_title="Disbanding Brazil",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==== Constants ====
DEFAULT_SHEET_ID = "1Jbb4p1cZCo67ZRiW5cmFUq-c9ijo5VMH_hFFMVYeJk4"
DEFAULT_WS_NAME  = "data"

# –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π ID –±–µ–∑ replace
EXT_GROUPS_SS_ID = "1u_NwMt3CVVgozm04JGmccyTsNZnZGiHjG5y0Ko3YdaY"
EXT_GROUPS_WS    = "Groups & Teachers"

RATING_SS_ID = "1HItT2-PtZWoldYKL210hCQOLg3rh6U1Qj6NWkBjDjzk"
RATING_WS    = "Rating"

# --- NEW: –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–ª—è –≤—Ç–æ—Ä–æ–π –≤–∫–ª–∞–¥–∫–∏ ---
EXTERNAL_SHEET_ID = "1XwyahhHC7uVzwfoErrvwrcruEjwewqIUp2u-6nvdSR0"
EXTERNAL_WS_NAME  = "data"

# --- NEW: —Ä–µ–π—Ç–∏–Ω–≥ –¥–ª—è –Ω–æ–≤–æ–π –≤–∫–ª–∞–¥–∫–∏ (–ª–∏—Å—Ç "Rating Col BU") ---
RATING2_SS_ID = "16QrbLtzLTV6GqyT8HYwzcwYIsXewzjUbM0Jy5i1fENE"
RATING2_WS    = "Rating"

SHEET_ID = os.getenv("GSHEET_ID") or st.secrets.get("GSHEET_ID", DEFAULT_SHEET_ID)
WS_NAME  = os.getenv("GSHEET_WS") or st.secrets.get("GSHEET_WS", DEFAULT_WS_NAME)

SCOPE = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]


def _authorize_client():
    sa_json = os.getenv("GCP_SERVICE_ACCOUNT") or st.secrets.get("GCP_SERVICE_ACCOUNT")
    if not sa_json:
        st.error("–ù–µ –Ω–∞–π–¥–µ–Ω —Å–µ—Ä–≤–∏—Å–Ω—ã–π –∫–ª—é—á. –î–æ–±–∞–≤—å GCP_SERVICE_ACCOUNT –≤ Secrets –∏–ª–∏ ENV.")
        st.stop()
    try:
        sa_info = json.loads(sa_json)
    except Exception:
        st.error("GCP_SERVICE_ACCOUNT –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å JSON-—Å—Ç—Ä–æ–∫–æ–π (–∞ –Ω–µ –æ–±—ä–µ–∫—Ç–æ–º).")
        st.stop()
    creds  = ServiceAccountCredentials.from_json_keyfile_dict(sa_info, SCOPE)
    client = gspread.authorize(creds)
    return client


@st.cache_data(show_spinner=False, ttl=300)
def load_sheet_df(sheet_id: str, worksheet_name: str = "data") -> pd.DataFrame:
    client = _authorize_client()
    sh = client.open_by_key(sheet_id)
    ws = sh.worksheet(worksheet_name)
    values = ws.get(
        "A:R",
        value_render_option="UNFORMATTED_VALUE",
        date_time_render_option="FORMATTED_STRING",
    )
    if not values:
        return pd.DataFrame()
    header = values[0]
    rows = values[1:]
    df = pd.DataFrame(rows, columns=header)
    df = df.replace({"": pd.NA})
    return df


def adjust_local_time_minus_3(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return df
    col = None
    for c in df.columns:
        name = str(c).strip().lower().replace("_", " ")
        if name == "local time":
            col = c
            break
    if col is None:
        if len(df.columns) >= 9:
            col = df.columns[8]
        else:
            return df

    s = df[col].astype(str).str.strip()
    time_only_mask = s.str.match(r"^\d{1,2}:\d{2}(:\d{2})?$", na=False)

    def _shift_time_str(v: str) -> str:
        parts = v.split(":")
        h = int(parts[0]); m = int(parts[1]); sec = int(parts[2]) if len(parts) > 2 else None
        h = (h - 3) % 24
        return f"{h:02d}:{m:02d}" + (f":{sec:02d}" if sec is not None else "")

    out = pd.Series(pd.NA, index=df.index, dtype="object")
    out.loc[time_only_mask] = s.loc[time_only_mask].apply(_shift_time_str)

    dt_mask = (~time_only_mask) & s.ne("")
    if dt_mask.any():
        dt = pd.to_datetime(s[dt_mask], errors="coerce", dayfirst=False)
        miss = dt.isna()
        if miss.any():
            dt2 = pd.to_datetime(s[dt_mask][miss], errors="coerce", dayfirst=True)
            dt.loc[miss] = dt2
        dt = dt - pd.Timedelta(hours=3)
        out.loc[dt_mask] = dt.dt.strftime("%Y-%m-%d %H:%M")

    df = df.copy()
    df[col] = out.where(out.notna(), df[col])
    return df


@st.cache_data(show_spinner=False, ttl=300)
def load_group_age_map(sheet_id: str = EXT_GROUPS_SS_ID, worksheet_name: str = EXT_GROUPS_WS) -> dict:
    try:
        client = _authorize_client()
        sh = client.open_by_key(sheet_id)
        ws = sh.worksheet(worksheet_name)
        vals = ws.get("A:E")
    except SpreadsheetNotFound:
        st.warning("–ù–µ –º–æ–≥—É –æ—Ç–∫—Ä—ã—Ç—å —Ç–∞–±–ª–∏—Ü—É EXT_GROUPS_SS_ID. –ü—Ä–æ–≤–µ—Ä—å ID –∏ –¥–æ—Å—Ç—É–ø —Å–µ—Ä–≤–∏—Å–Ω–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞.")
        return {}
    except WorksheetNotFound:
        st.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω –ª–∏—Å—Ç '{worksheet_name}' –≤ EXT_GROUPS_SS_ID.")
        return {}
    except Exception as e:
        st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ EXT_GROUPS_SS_ID: {e}")
        return {}
    if not vals or len(vals) < 2:
        return {}
    rows = vals[1:]
    mapping = {}
    for r in rows:
        if len(r) >= 5:
            key = str(r[0]).strip()
            val = r[4]
            if key:
                mapping[key] = val
    return mapping


def replace_group_age_from_map(df: pd.DataFrame, mapping: dict) -> pd.DataFrame:
    """–ü–æ–¥—Å—Ç–∞–≤–ª—è–µ–º Group age –∏–∑ –≤–Ω–µ—à–Ω–µ–π –∫–∞—Ä—Ç—ã –ø–æ –∫–æ–ª–æ–Ω–∫–µ B (Group/ID/Title).
       –ï—Å–ª–∏ –≤ mapping –Ω–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ.
    """
    if df.empty or not mapping:
        return df.copy()

    dff = df.copy()

    # –∏—â–µ–º –∫–æ–ª–æ–Ω–∫—É B (group id/title) –ø–æ —Å–∏–Ω–æ–Ω–∏–º–∞–º
    colB = None
    for c in dff.columns:
        if str(c).strip().lower().replace("_", " ") in (
            "b", "group id", "group", "group title", "group_name", "group name"
        ):
            colB = c
            break
    if colB is None:
        colB = dff.columns[1] if len(dff.columns) >= 2 else None

    # –∏—â–µ–º –∫–æ–ª–æ–Ω–∫—É Group age
    colG = None
    for c in dff.columns:
        if str(c).strip().lower().replace("_", " ") == "group age":
            colG = c
            break
    if colG is None:
        colG = dff.columns[6] if len(dff.columns) >= 7 else None

    if colB is None or colG is None:
        return dff

    keys = dff[colB].astype(str).str.strip()
    new_vals = keys.map(lambda k: mapping.get(k, pd.NA))

    # –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ mapping
    dff[colG] = new_vals.where(new_vals.notna() & (new_vals.astype(str).str.strip() != ""), dff[colG])
    return dff


@st.cache_data(show_spinner=False, ttl=300)
def load_rating_bp_map(sheet_id: str = RATING_SS_ID, worksheet_name: str = RATING_WS) -> dict:
    try:
        client = _authorize_client()
        ws = client.open_by_key(sheet_id).worksheet(worksheet_name)
        vals = ws.get(
            "A:BP",
            value_render_option="UNFORMATTED_VALUE",
            date_time_render_option="FORMATTED_STRING",
        )
    except SpreadsheetNotFound:
        st.warning("–ù–µ –º–æ–≥—É –æ—Ç–∫—Ä—ã—Ç—å —Ç–∞–±–ª–∏—Ü—É RATING_SS_ID. –ü—Ä–æ–≤–µ—Ä—å ID –∏ –¥–æ—Å—Ç—É–ø —Å–µ—Ä–≤–∏—Å–Ω–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞.")
        return {}
    except WorksheetNotFound:
        st.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω –ª–∏—Å—Ç '{worksheet_name}' –≤ RATING_SS_ID.")
        return {}
    except Exception as e:
        st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ RATING_SS_ID: {e}")
        return {}
    if not vals or len(vals) < 2:
        return {}
    mapping = {}
    for r in vals[1:]:
        a  = str(r[0]).strip() if len(r) >= 1  else ""
        bp = r[67]              if len(r) >= 68 else None  # BP = 68-—è –∫–æ–ª–æ–Ω–∫–∞
        if a:
            mapping[a] = bp
    return mapping

@st.cache_data(show_spinner=False, ttl=300)
def load_rating_bu_map(sheet_id: str = RATING2_SS_ID, worksheet_name: str = RATING2_WS) -> dict:
    """
    –ß–∏—Ç–∞–µ—Ç —Ä–µ–π—Ç–∏–Ω–≥ –∏–∑ –ª–∏—Å—Ç–∞ 'Rating': –∫–ª—é—á = –∫–æ–ª–æ–Ω–∫–∞ A, –∑–Ω–∞—á–µ–Ω–∏–µ = –∫–æ–ª–æ–Ω–∫–∞ BU.
    """
    try:
        client = _authorize_client()
        ws = client.open_by_key(sheet_id).worksheet(worksheet_name)
        vals = ws.get(
            "A:BU",  # BU = 73-—è –∫–æ–ª–æ–Ω–∫–∞ (index 72)
            value_render_option="UNFORMATTED_VALUE",
            date_time_render_option="FORMATTED_STRING",
        )
    except SpreadsheetNotFound:
        st.warning("–ù–µ –º–æ–≥—É –æ—Ç–∫—Ä—ã—Ç—å —Ç–∞–±–ª–∏—Ü—É RATING2_SS_ID. –ü—Ä–æ–≤–µ—Ä—å ID –∏ –¥–æ—Å—Ç—É–ø —Å–µ—Ä–≤–∏—Å–Ω–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞.")
        return {}
    except WorksheetNotFound:
        st.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω –ª–∏—Å—Ç '{worksheet_name}' –≤ RATING2_SS_ID.")
        return {}
    except Exception as e:
        st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ RATING2_SS_ID: {e}")
        return {}

    if not vals or len(vals) < 2:
        return {}

    mapping = {}
    for r in vals[1:]:
        a  = str(r[0]).strip() if len(r) >= 1  else ""
        bu = r[72]             if len(r) >= 73 else None  # BU
        if a:
            mapping[a] = bu
    return mapping



def add_rating_bp_by_O(df: pd.DataFrame, mapping: dict, new_col_name: str = "Rating_BP") -> pd.DataFrame:
    if df.empty or not mapping:
        return df.copy()
    if len(df.columns) < 15:
        return df.copy()
    colO = df.columns[14]  # O
    keys = df[colO].astype(str).str.strip()
    out = df.copy()
    name = new_col_name
    while name in out.columns:
        name += "_x"
    out[name] = keys.map(lambda k: mapping.get(k, pd.NA))
    return out


def filter_df(df: pd.DataFrame) -> pd.DataFrame:
    """–ë–∞–∑–æ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã + –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π: –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ (Capacity - Paid) >= 1.
       –ü–æ R –±–µ—Ä—ë–º, –µ—Å–ª–∏ –ø—É—Å—Ç–æ/NaN/0/"0".
    """
    if df.empty:
        return df
    if len(df.columns) < 18:
        st.error("–û–∂–∏–¥–∞–ª–æ—Å—å –º–∏–Ω–∏–º—É–º 18 –∫–æ–ª–æ–Ω–æ–∫ (–¥–æ R). –ü—Ä–æ–≤–µ—Ä—å –¥–∏–∞–ø–∞–∑–æ–Ω A:R –∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏.")
        st.stop()

    colD, colK = df.columns[3], df.columns[10]
    colL, colM = df.columns[11], df.columns[12]
    colP, colQ, colR = df.columns[15], df.columns[16], df.columns[17]

    # –ë–∞–∑–æ–≤—ã–µ –ø–æ–ª—è
    d_active = df[colD].astype(str).str.strip().str.lower() == "active"

    k_num = pd.to_numeric(df[colK], errors="coerce")
    k_ok  = k_num.notna() & (k_num > 3) & (k_num < 32)

    # R: –æ–∫, –µ—Å–ª–∏ –ø—É—Å—Ç–æ/NaN/0/"0"
    r_str = df[colR].astype(str).str.strip().str.lower()
    r_num = pd.to_numeric(df[colR], errors="coerce")
    r_ok  = df[colR].isna() | (r_str == "") | (r_str == "0") | (r_num == 0)

    # P/Q (—Ñ–ª–∞–≥–∏), L/M (–∏—Å–∫–ª—é—á–µ–Ω–∏—è)
    p_true = (df[colP] == True) | (df[colP].astype(str).str.strip().str.lower() == "true")
    q_true = (df[colQ] == True) | (df[colQ].astype(str).str.strip().str.lower() == "true")

    l_num = pd.to_numeric(df[colL], errors="coerce")
    m_num = pd.to_numeric(df[colM], errors="coerce")

    exclude_m = (m_num > 0)
    exclude_l = (l_num > 2)

    # –ò—Ç–æ–≥–æ–≤–∞—è –º–∞—Å–∫–∞
    mask = d_active & k_ok & r_ok & ~p_true & ~q_true & ~exclude_m & ~exclude_l

    # --- –î–û–ü. –§–ò–õ–¨–¢–†: –µ—Å—Ç—å —Å–≤–æ–±–æ–¥–Ω—ã–µ –º–µ—Å—Ç–∞ (Capacity - Paid >= 1) ---
    def _norm(s: str) -> str:
        return str(s).strip().lower().replace("_", " ").replace("-", " ")

    paid_aliases = {"paid students", "paid student", "paid"}
    cap_aliases  = {"capacity", "cap"}
    colPaid = colCap = None
    for c in df.columns:
        n = _norm(c)
        if colPaid is None and n in paid_aliases:
            colPaid = c
        if colCap  is None and n in cap_aliases:
            colCap  = c
        if colPaid is not None and colCap is not None:
            break

    free_slots = None
    paid_pct_series = None
    if colPaid is not None and colCap is not None:
        paid_num = pd.to_numeric(df[colPaid], errors="coerce")
        cap_num  = pd.to_numeric(df[colCap],  errors="coerce")
        free_slots = (cap_num - paid_num)
        have_free  = (cap_num.notna() & paid_num.notna()) & (free_slots >= 1)
        mask = mask & have_free

        # Paid % = round(Paid/Capacity*100), —Ñ–æ—Ä–º–∞—Ç —Å—Ç—Ä–æ–∫–æ–π "NN%"
        with np.errstate(divide="ignore", invalid="ignore"):
            pct = np.where(cap_num > 0, (paid_num / cap_num) * 100.0, np.nan)
        paid_pct_series = pd.Series(pct, index=df.index)
        paid_pct_series = paid_pct_series.apply(lambda x: f"{int(round(x))}%"
                                                if pd.notna(x) else pd.NA)

    out = df.loc[mask].copy()
    out[colK] = k_num.loc[out.index]

    # –î–æ–±–∞–≤–∏–º –∫–æ–ª–æ–Ω–∫–∏ Free slots –∏ Paid % (–µ—Å–ª–∏ –Ω–∞—à–ª–∏ Paid/Capacity)
    if (colPaid is not None) and (colCap is not None) and (free_slots is not None):
        out["Free slots"] = free_slots.loc[out.index]
        if paid_pct_series is not None:
            out["Paid %"] = paid_pct_series.loc[out.index]

    return out


def to_excel_bytes(data: pd.DataFrame) -> io.BytesIO | None:
    try:
        import xlsxwriter  # noqa: F401
        buf = io.BytesIO()
        with pd.ExcelWriter(buf, engine="xlsxwriter") as writer:
            data.to_excel(writer, index=False)
        buf.seek(0)
        return buf
    except Exception:
        return None


# --- —É—Ç–∏–ª–∏—Ç—ã –º–∞—Ç—á–∏–Ω–≥–∞ ---

def _time_to_minutes(v: str) -> float:
    """I –≤—Å–µ–≥–¥–∞ HH:MM."""
    if v is None or pd.isna(v): return np.nan
    s = str(v).strip()
    if not re.fullmatch(r"\d{1,2}:\d{2}", s):
        return np.nan
    h, m = s.split(":")
    return int(h) * 60 + int(m)

def _find_rating_col(df: pd.DataFrame) -> str | None:
    if "Rating_BP" in df.columns:
        return "Rating_BP"
    for c in df.columns:
        n = str(c).strip().lower()
        if "rating" in n:
            return c
    return None

def _find_free_slots_col(df: pd.DataFrame) -> str | None:
    for c in df.columns:
        if str(c).strip().lower() == "free slots":
            return c
    return None

def _norm_rating(x: str) -> str:
    if x is None or pd.isna(x): return ""
    s = str(x).strip().lower()
    repl = {
        "amazing": "amazing",
        "good": "good",
        "ok": "ok",
        "new tutor (good)": "new_tutor_good",
        "new tutor (ok)": "new_tutor_ok",
        "new tutor (bad)": "new_tutor_bad",
        "new tutor": "new_tutor",
        "bad": "bad",
    }
    for k in sorted(repl.keys(), key=len, reverse=True):
        if s == k:
            return repl[k]
    return s

def can_pair(my_rating_raw: str, cand_rating_raw: str) -> bool:
    """–ü—Ä–∞–≤–∏–ª–æ –ø–∞—Ä –ø–æ —Ä–µ–π—Ç–∏–Ω–≥–∞–º –∏–∑ –¢–ó."""
    my   = _norm_rating(my_rating_raw)
    cand = _norm_rating(cand_rating_raw)

    NEVER = {"bad", "new_tutor_bad"}
    if cand in NEVER:
        return False

    HIGH  = {"amazing", "good", "new_tutor_good"}
    OKISH = {"ok", "new_tutor_ok"}

    if cand in OKISH:
        return my not in (HIGH | {"new_tutor"})  # –Ω–µ –∫ high –∏ –Ω–µ –∫ 'new_tutor'
    if cand == "new_tutor":
        return my not in HIGH                    # –Ω–µ –∫ high
    if cand in HIGH:
        return True

    return True  # –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ —è—Ä–ª—ã–∫–∏ ‚Äî —Ä–∞–∑—Ä–µ—à–∞–µ–º


def _b_suffix3(s: str) -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç 3 –±—É–∫–≤—ã:
      - –µ—Å–ª–∏ –≤ B –µ—Å—Ç—å >= 2 –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–π ‚Äî –±–µ—Ä—ë–º 3 –±—É–∫–≤—ã –ø–æ—Å–ª–µ –≤—Ç–æ—Ä–æ–≥–æ '_'
      - –µ—Å–ª–∏ —Ä–æ–≤–Ω–æ 1 –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ ‚Äî –±–µ—Ä—ë–º 3 –±—É–∫–≤—ã –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ '_'
      - –∏–Ω–∞—á–µ ""
    """
    if s is None or pd.isna(s):
        return ""
    s = str(s).upper()
    parts = s.split("_")
    if len(parts) >= 3:
        tail = parts[2]
    elif len(parts) == 2:
        tail = parts[1]
    else:
        return ""
    letters = "".join(ch for ch in tail if ch.isalpha())
    return letters[:3] if len(letters) >= 3 else ""

def dbg(tag, df):
    try:
        st.write(f"üîé {tag}: {df.shape}")
    except Exception:
        pass

# --- –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–µ Matches (time¬±120 –ò–õ–ò suffix3 —Ä–∞–≤–µ–Ω), + –±–∞–∑–æ–≤—ã–µ —É—Å–ª–æ–≤–∏—è ---
def add_matches_combined(df: pd.DataFrame, new_col_name="Matches") -> pd.DataFrame:
    if df.empty:
        return df

    colB, colE, colF, colG = df.columns[1], df.columns[4], df.columns[5], df.columns[6]
    colI, colK             = df.columns[8], df.columns[10]
    rating_col             = _find_rating_col(df)

    f_vals = df[colF].astype(str).str.strip()
    g_vals = df[colG].astype(str).str.strip()
    b_vals = df[colB].astype(str).fillna("").str.upper()
    k_num  = pd.to_numeric(df[colK], errors="coerce")
    i_mins = df[colI].astype(str).str.strip().apply(_time_to_minutes)
    suf3   = b_vals.apply(_b_suffix3)
    b_is_prm = b_vals.str.contains("PRM", na=False)

    r_vals = df[rating_col].astype(str) if rating_col else pd.Series("", index=df.index)
    slots_col = _find_free_slots_col(df)

    lines, counts = [], []
    for i in range(len(df)):
        same_course = (f_vals == f_vals.iloc[i])
        same_age    = (g_vals == g_vals.iloc[i])

        base_k = k_num.iloc[i]
        close_k = pd.Series(False, index=df.index)
        if not pd.isna(base_k):
            close_k = (k_num.sub(base_k).abs() <= 1)

        base_t = i_mins.iloc[i]
        close_time = pd.Series(False, index=df.index)
        if not pd.isna(base_t):
            close_time = (i_mins.sub(base_t).abs() <= 120)

        same_suf = (suf3 == suf3.iloc[i])
        same_prm = (b_is_prm == b_is_prm.iloc[i])

        my_r = r_vals.iloc[i]
        ok_by_rating = r_vals.apply(lambda rr: can_pair(my_r, rr))

        mask = same_course & same_age & close_k & same_prm & ok_by_rating & (close_time | same_suf)
        mask.iloc[i] = False

        if mask.any():
            # –î–ª—è –≤—ã–≤–æ–¥–∞ –±–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ B, E, K (+ Rating –∏ Free slots)
            cols_take = [colB, colE, colK]
            cols_take = [c for c in cols_take if c in df.columns]
            sub = df.loc[mask, cols_take].copy()

            sub["_rating"] = r_vals.loc[sub.index].values
            sub["_slots"]  = df.loc[sub.index, slots_col].values if slots_col else ""

            lst = [
                f"- {row[colB]}, "
                f"Tutor: {row[colE]}, "
                f"Rating: {row['_rating']}, "
                f"lesson: {row[colK]}, "
                f"slots: {row['_slots']}"
                for _, row in sub.iterrows()
            ]
            lines.append("\n".join(lst)); counts.append(len(lst))
        else:
            lines.append(""); counts.append(0)

    out = df.copy()
    name = new_col_name
    while name in out.columns: name += "_x"
    cnt = f"{new_col_name}_count"
    while cnt in out.columns: cnt += "_x"
    out[name] = lines
    out[cnt]  = counts
    return out


# --- WideMatches: –±–µ–∑ –≤—Ä–µ–º–µ–Ω–∏/—Å—É—Ñ—Ñ–∏–∫—Å–∞, —Å–º–æ—Ç—Ä–∏–º –∏ –≤–≤–µ—Ä—Ö, –∏ –≤–Ω–∏–∑; –Ω–µ –∏—Å–∫–ª—é—á–∞–µ–º —Ç–µ—Ö, —É –∫–æ–≥–æ —É–∂–µ –µ—Å—Ç—å Matches ---
def add_wide_matches_column(df: pd.DataFrame, new_col_name="WideMatches", exclude_col="Matches") -> pd.DataFrame:
    """
    WideMatches: –±–µ–∑ –≤—Ä–µ–º–µ–Ω–∏ –∏ –±–µ–∑ —Å—É—Ñ—Ñ–∏–∫—Å–∞, —Å–º–æ—Ç—Ä–∏–º –∏ –≤–≤–µ—Ä—Ö, –∏ –≤–Ω–∏–∑.
    –ù–ï –≤–∫–ª—é—á–∞–µ–º —Ç–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ Matches —ç—Ç–æ–π –∂–µ —Å—Ç—Ä–æ–∫–∏.
    –£—Å–ª–æ–≤–∏—è: same course & same age & |K-K'| <= 1 & –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π PRM-—Å—Ç–∞—Ç—É—Å & —Ä–µ–π—Ç–∏–Ω–≥–∏ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã.
    """
    if df.empty:
        return df

    colB, colE, colF, colG = df.columns[1], df.columns[4], df.columns[5], df.columns[6]
    colI, colK             = df.columns[8], df.columns[10]  # colI –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º, –æ—Å—Ç–∞–≤–ª–µ–Ω –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    rating_col             = _find_rating_col(df)

    f_vals = df[colF].astype(str).str.strip()
    g_vals = df[colG].astype(str).str.strip()
    b_vals = df[colB].astype(str).fillna("").str.upper()
    k_num  = pd.to_numeric(df[colK], errors="coerce")
    b_is_prm = b_vals.str.contains("PRM", na=False)

    r_vals = df[rating_col].astype(str) if rating_col else pd.Series("", index=df.index)
    slots_col = _find_free_slots_col(df)

    lines, counts = [], []
    for i in range(len(df)):
        same_course = (f_vals == f_vals.iloc[i])
        same_age    = (g_vals == g_vals.iloc[i])

        base_k = k_num.iloc[i]
        if pd.isna(base_k):
            close_k = pd.Series(False, index=df.index)
        else:
            close_k = (k_num.sub(base_k).abs() <= 1)

        same_prm = (b_is_prm == b_is_prm.iloc[i])

        my_r = r_vals.iloc[i]
        ok_by_rating = r_vals.apply(lambda rr: can_pair(my_r, rr))

        # –ë–∞–∑–æ–≤–∞—è —à–∏—Ä–æ–∫–∞—è –º–∞—Å–∫–∞
        mask = same_course & same_age & close_k & same_prm & ok_by_rating
        mask.iloc[i] = False  # –Ω–µ –º–∞—Ç—á–∏–º —Å–∞–º–∏ –Ω–∞ —Å–µ–±—è

        # --- –ù–û–í–û–ï: –∏—Å–∫–ª—é—á–∞–µ–º —Ç–æ, —á—Ç–æ —É–∂–µ –µ—Å—Ç—å –≤ Matches —ç—Ç–æ–π —Å—Ç—Ä–æ–∫–∏ ---
        if exclude_col in df.columns:
            ex_text = df.iloc[i][exclude_col]
            ex_set = set()
            if pd.notna(ex_text):
                for line in str(ex_text).splitlines():
                    # —Å—Ç—Ä–æ–∫–∏ –≤–∏–¥–∞: "- <GroupID>, Tutor: ..., Rating: ..., lesson: ..., slots: ..."
                    m = re.match(r"^\s*-\s*(.*?),", line)
                    if m:
                        ex_set.add(m.group(1).strip())
            if ex_set:
                mask = mask & ~df[colB].astype(str).isin(ex_set)
        # --- –∫–æ–Ω–µ—Ü –Ω–æ–≤–æ–≥–æ –±–ª–æ–∫–∞ ---

        if mask.any():
            cols_take = [colB, colE, colK]
            cols_take = [c for c in cols_take if c in df.columns]
            sub = df.loc[mask, cols_take].copy()

            sub["_rating"] = r_vals.loc[sub.index].values
            sub["_slots"]  = df.loc[sub.index, slots_col].values if slots_col else ""

            lst = [
                f"- {row[colB]}, "
                f"Tutor: {row[colE]}, "
                f"Rating: {row['_rating']}, "
                f"lesson: {row[colK]}, "
                f"slots: {row['_slots']}"
                for _, row in sub.iterrows()
            ]
            lines.append("\n".join(lst)); counts.append(len(lst))
        else:
            lines.append(""); counts.append(0)

    out = df.copy()
    name = new_col_name
    while name in out.columns:
        name += "_x"
    cnt = f"{new_col_name}_count"
    while cnt in out.columns:
        cnt += "_x"
    out[name] = lines
    out[cnt]  = counts
    return out


# ---- –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä –∏–º—ë–Ω –∏ –≤—ã–±–æ—Ä –∫–æ–ª–æ–Ω–æ–∫ –ø–æ —Å–∏–Ω–æ–Ω–∏–º–∞–º ----
def _norm_name(s: str) -> str:
    return re.sub(r"\s+", " ", str(s).strip().lower())

def _pick_col(df: pd.DataFrame, candidates: set[str], fallback_idx: int | None = None) -> str | None:
    norm = {_norm_name(c): c for c in df.columns}
    for key in candidates:
        if key in norm:
            return norm[key]
    if fallback_idx is not None and fallback_idx < len(df.columns):
        return df.columns[fallback_idx]
    return None

def exclude_c6_h_before_14d(df: pd.DataFrame) -> pd.DataFrame:
    """
    –ò—Å–∫–ª—é—á–∏—Ç—å —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ C == 6 –∏ H < (—Å–µ–≥–æ–¥–Ω—è - 14 –¥–Ω–µ–π).
    C ‚Äî 3-—è –∫–æ–ª–æ–Ω–∫–∞ (index 2), H ‚Äî 8-—è (index 7) –ø—Ä–∏ –∏—Å—Ö–æ–¥–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ A:R.
    """
    if df.empty or len(df.columns) < 8:
        return df

    col_c = df.columns[2]  # C
    col_h = df.columns[7]  # H

    c_num = pd.to_numeric(df[col_c], errors="coerce")

    # —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º ISO/US, –∑–∞—Ç–µ–º fallback –Ω–∞ dayfirst
    h_dt = pd.to_datetime(df[col_h], errors="coerce", dayfirst=False, infer_datetime_format=True)
    miss = h_dt.isna()
    if miss.any():
        h_dt.loc[miss] = pd.to_datetime(df.loc[miss, col_h], errors="coerce", dayfirst=True)

    cutoff = pd.Timestamp.today().normalize() - pd.Timedelta(days=14)
    mask_exclude = (c_num == 6) & h_dt.notna() & (h_dt < cutoff)
    return df.loc[~mask_exclude].copy()

def main():
    st.title("Disbanding Brazil")

    st.markdown(textwrap.dedent("""\
    ### Legend

    **Which rows are included**
    - Status: **Active**
    - **Lesson number**: 4‚Äì31 (inclusive)
    - **No 0-2 lessons left**
    - **Not flagged as "Do not disband" or "Do not merge"**
    - **Students transferred 1 time** ‚â§ 2; **Students transferred 2+ times** ‚â§ 0
    - **Free slots** ‚â• 1 (Capacity ‚àí Paid), when both **Capacity** & **Paid** exist

    **Matches (strict)**
    - Same **Course** and same **Group age**
    - **Lesson number** within **¬±1**
    - Same **PRM** marker (both PRM or both not)
    - **Either** same local start time within **¬±120 minutes** **or** the same **day**
    - Rating pairing allowed:
      - **Bad** / **New tutor (Bad)** ‚Üí never
      - **OK** / **New tutor (OK)** ‚Üí not with **Amazing/Good/New tutor (Good)** and not with **New tutor**
      - **New tutor** ‚Üí not with **Amazing/Good/New tutor (Good)**
      - **Amazing/Good/New tutor (Good)** ‚Üí allowed with anyone
    - Excludes the current row itself

    **WideMatches (broad)**
    - Same **Course** and **Group age**
    - **Lesson number** within **¬±1**
    - Same **PRM**
    - Rating pairing allowed (same rules as above)
    - **No** time/day requirement
    """))
    st.divider()

    # === –î–í–ï –í–ö–õ–ê–î–ö–ò: –æ—Å–Ω–æ–≤–Ω–∞—è –∏ –≤–Ω–µ—à–Ω—è—è ===
    tabs = st.tabs(["Main data", "External data"])

    # ---------- TAB 1: –û–°–ù–û–í–ù–ê–Ø (–∫–∞–∫ –±—ã–ª–æ) ----------
    with tabs[0]:
        sheet_id = SHEET_ID
        ws_name  = WS_NAME

        try:
            client = _authorize_client()
            sh = client.open_by_key(sheet_id)
            ws_names = [ws.title for ws in sh.worksheets()]
            if ws_name not in ws_names and ws_names:
                ws_name = ws_names[0]
        except Exception:
            pass

        with st.spinner("Loading MAIN data‚Ä¶"):
            df = load_sheet_df(sheet_id, ws_name)

        if df.empty:
            st.warning(f"–ü—É—Å—Ç–æ: –ø—Ä–æ–≤–µ—Ä—å –≤–∫–ª–∞–¥–∫—É '{ws_name}' –∏ –¥–æ—Å—Ç—É–ø —Å–µ—Ä–≤–∏—Å–Ω–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞ (Viewer/Editor).")
        else:
            df = adjust_local_time_minus_3(df)
            mapping = load_group_age_map()
            df = replace_group_age_from_map(df, mapping)

            rating_map = load_rating_bp_map()  # —Å—Ç–∞—Ä—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ —Ä–µ–π—Ç–∏–Ω–≥–∞
            df = add_rating_bp_by_O(df, rating_map, new_col_name="Rating_BP")

            filtered = filter_df(df)
            filtered = add_matches_combined(filtered, new_col_name="Matches")
            filtered = add_wide_matches_column(filtered, new_col_name="WideMatches", exclude_col="Matches")

            c1, c2 = st.columns(2)
            c1.caption(f"Rows total: {len(df)}")

            # --- Sidebar Filters (MAIN) ---
            dff = filtered.copy()

            col_group      = _pick_col(dff, {"group", "group title", "group name", "group id"}, fallback_idx=1)
            col_tutor      = _pick_col(dff, {"tutor", "teacher", "tutor name", "teacher name"}, fallback_idx=4)
            col_tutor_id   = _pick_col(dff, {"tutor id", "teacher id", "id"}, fallback_idx=14)
            col_course     = _pick_col(dff, {"course"}, fallback_idx=5)
            col_group_age  = _pick_col(dff, {"group age", "age"}, fallback_idx=6)
            col_local_time = _pick_col(dff, {"local time", "localtime", "time (local)"}, fallback_idx=8)
            col_module     = _pick_col(dff, {"module"}, fallback_idx=2)
            col_lesson_num = _pick_col(dff, {"lesson number", "lesson", "lesson_num"}, fallback_idx=13)
            col_capacity   = _pick_col(dff, {"capacity", "cap"})
            col_paid       = _pick_col(dff, {"paid students", "paid student", "paid"})
            col_transfer1  = _pick_col(dff, {"students transferred 1 time", "transferred 1 time"}, fallback_idx=11)
            col_paid_pct   = _pick_col(dff, {"paid %", "paid percent", "paid percentage", "paid pct"})

            col_m_text  = "Matches"           if "Matches"           in dff.columns else None
            col_m_cnt   = "Matches_count"     if "Matches_count"     in dff.columns else None
            col_w_text  = "WideMatches"       if "WideMatches"       in dff.columns else None
            col_w_cnt   = "WideMatches_count" if "WideMatches_count" in dff.columns else None

            def _ms_options(df_, col):
                if not col or col not in df_.columns:
                    return []
                return sorted(df_[col].dropna().astype(str).unique())

            def _apply_ms(df_, col, sel):
                if not col or not sel:
                    return df_
                return df_[df_[col].astype(str).isin(sel)]

            with st.sidebar.expander("Filters (Main)", expanded=True):
                dff = _apply_ms(dff, col_group,      st.multiselect("Group",      _ms_options(dff, col_group), key="ms_group_main"))
                dff = _apply_ms(dff, col_tutor,      st.multiselect("Tutor",      _ms_options(dff, col_tutor), key="ms_tutor_main"))
                dff = _apply_ms(dff, col_tutor_id,   st.multiselect("Tutor ID",   _ms_options(dff, col_tutor_id), key="ms_tid_main"))
                dff = _apply_ms(dff, col_course,     st.multiselect("Course",     _ms_options(dff, col_course), key="ms_course_main"))
                dff = _apply_ms(dff, col_group_age,  st.multiselect("Group age",  _ms_options(dff, col_group_age), key="ms_age_main"))
                dff = _apply_ms(dff, col_local_time, st.multiselect("Local time", _ms_options(dff, col_local_time), key="ms_time_main"))
                dff = _apply_ms(dff, col_module,     st.multiselect("Module",     _ms_options(dff, col_module), key="ms_module_main"))

                dff = _apply_ms(dff, col_lesson_num, st.multiselect("Lesson number", _ms_options(dff, col_lesson_num), key="ms_lesson_main"))
                dff = _apply_ms(dff, col_capacity,   st.multiselect("Capacity",      _ms_options(dff, col_capacity), key="ms_cap_main"))
                dff = _apply_ms(dff, col_paid,       st.multiselect("Paid students", _ms_options(dff, col_paid), key="ms_paid_main"))
                dff = _apply_ms(dff, col_paid_pct,   st.multiselect("Paid %",        _ms_options(dff, col_paid_pct), key="ms_paidpct_main"))
                dff = _apply_ms(dff, col_transfer1,  st.multiselect("Students transferred 1 time", _ms_options(dff, col_transfer1), key="ms_tr1_main"))

                if col_m_cnt:
                    min_m = st.number_input("Min Matches",      min_value=0, value=0, step=1, key="min_m_main")
                    dff = dff[pd.to_numeric(dff[col_m_cnt], errors="coerce").fillna(0).astype(int) >= min_m]
                if col_w_cnt:
                    min_w = st.number_input("Min Wide matches", min_value=0, value=0, step=1, key="min_w_main")
                    dff = dff[pd.to_numeric(dff[col_w_cnt], errors="coerce").fillna(0).astype(int) >= min_w]

                q = st.text_input("Search in matches text", key="q_main")
                if q:
                    qrx = re.escape(q)
                    mask = pd.Series(False, index=dff.index)
                    for col in [col_m_text, col_w_text]:
                        if col:
                            mask |= dff[col].astype(str).str.contains(qrx, case=False, na=False)
                    dff = dff[mask]

                only_any = st.checkbox("Only rows with any matches", value=False, key="only_any_main")
                if only_any:
                    cnt = pd.Series(0, index=dff.index)
                    for col in [col_m_cnt, col_w_cnt]:
                        if col:
                            cnt = cnt.add(pd.to_numeric(dff[col], errors="coerce").fillna(0).astype(int), fill_value=0)
                    dff = dff[cnt > 0]

            st.success(f"Filtered rows: {len(dff)}")

            cols_all = list(dff.columns)
            def col(idx):
                return cols_all[idx] if idx < len(cols_all) else None

            colA, colB, colC = col(0), col(1), col(2)
            colE, colF, colG = col(4), col(5), col(6)
            colI, colJ, colK = col(8), col(9), col(10)
            colL, colN, colO = col(11), col(13), col(14)

            rating_colname = _find_rating_col(dff)
            desired = [
                colA, colB, colE, colO, rating_colname,
                colF, colG, colI,
                _pick_col(dff, {"capacity","cap"}), _pick_col(dff, {"paid students","paid student","paid"}), "Free slots", "Paid %",
                colK, colC, colN, colL,
                "Matches_count", "Matches",
                "WideMatches_count", "WideMatches",
            ]
            display_cols = [c for c in desired if (c is not None and c in dff.columns)]
            seen = set()
            display_cols = [c for c in display_cols if not (c in seen or seen.add(c))]
            curated = dff.loc[:, display_cols].copy()
            curated = curated.loc[:, ~curated.columns.duplicated()]
            if rating_colname and rating_colname in curated.columns:
                curated.rename(columns={rating_colname: "Rating"}, inplace=True)

            def _to_na(v):
                if v is None or pd.isna(v): return pd.NA
                if isinstance(v, str):
                    s = (v.replace("\u00A0"," ").replace("\u200B","").replace("\u200C","").replace("\u200D","").replace("\uFEFF","").strip())
                    if s == "" or s.lower() in {"nan","none","null","na"}: return pd.NA
                    return s
                return v
            curated = curated.applymap(_to_na)

            count_cols = [c for c in ["Matches_count","WideMatches_count"] if c in curated.columns]
            text_cols  = [c for c in ["Matches","WideMatches"] if c in curated.columns]
            base_cols  = [c for c in curated.columns if c not in (count_cols + text_cols)]
            has_base   = curated[base_cols].notna().any(axis=1) if base_cols else False
            has_text   = curated[text_cols].notna().any(axis=1) if text_cols else False
            has_counts = (sum(pd.to_numeric(curated[c], errors="coerce").fillna(0).astype(int) for c in count_cols) > 0) if count_cols else False
            curated = curated[ has_base | has_text | has_counts ].reset_index(drop=True)

            ROW, HEADER, PAD = 34, 39, 8
            table_h = min(700, HEADER + ROW * max(1, len(curated)))

            cfg = {}
            for c in ["BO","Group","Tutor","Course","Matches","WideMatches"]:
                if c in curated.columns: cfg[c] = st.column_config.TextColumn(label=c, width="large")
            for c in ["Lesson number","Capacity","Paid students","Free slots","Paid %","Students transferred 1 time",
                      "Module","Group age","Local time","Matches_count","WideMatches_count"]:
                if c in curated.columns: cfg[c] = st.column_config.TextColumn(label=c, width="small")

            st.dataframe(curated, use_container_width=True, height=table_h, column_config=cfg)
            st.download_button("‚¨áÔ∏è Download CSV (curated)", curated.to_csv(index=False).encode("utf-8"),
                               file_name="curated_view.csv", mime="text/csv")

    # ---------- TAB 2: –í–ù–ï–®–ù–ò–ô –§–ê–ô–õ + –ø—Ä–∞–≤–∏–ª–æ C/H + —Ä–µ–π—Ç–∏–Ω–≥ –∏–∑ BU ----------
    with tabs[1]:
        with st.spinner("Loading EXTERNAL data‚Ä¶"):
            df_ext = load_sheet_df(EXTERNAL_SHEET_ID, EXTERNAL_WS_NAME)
            
        st.subheader("Debug (External)")
        dbg("raw", df_ext)
    
        if df_ext.empty:
            st.warning(f"–ü—É—Å—Ç–æ: –ø—Ä–æ–≤–µ—Ä—å —Ñ–∞–π–ª '{EXTERNAL_SHEET_ID}', –≤–∫–ª–∞–¥–∫—É '{EXTERNAL_WS_NAME}' –∏ –¥–æ—Å—Ç—É–ø.")
        else:
            # –ø—Ä–∞–≤–∏–ª–æ C/H
            df_ext = exclude_c6_h_before_14d(df_ext)
            dbg("after C/H", df_ext)
    
            # –æ—Å—Ç–∞–ª—å–Ω–æ–π –ø–∞–π–ø–ª–∞–π–Ω
            df_ext = adjust_local_time_minus_3(df_ext)
            dbg("after time -3h", df_ext)
    
            mapping = load_group_age_map()
            df_ext = replace_group_age_from_map(df_ext, mapping)
            dbg("after group age", df_ext)
    
            rating_map2 = load_rating_bu_map()   # <--- —Ä–µ–π—Ç–∏–Ω–≥ –∏–∑ BU (–ª–∏—Å—Ç Rating)
            df_ext = add_rating_bp_by_O(df_ext, rating_map2, new_col_name="Rating_BP")
            dbg("after rating", df_ext)
    
            # –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä—É–µ–º, –Ω–∞–π–¥–µ–Ω—ã –ª–∏ Capacity/Paid
            def _norm(s): 
                return str(s).strip().lower().replace("_"," ").replace("-"," ")
            colPaid = colCap = None
            for c in df_ext.columns:
                n = _norm(c)
                if colPaid is None and n in {"paid students","paid student","paid"}:
                    colPaid = c
                if colCap is None and n in {"capacity","cap"}:
                    colCap = c
            st.write(f"üß≠ cap='{colCap}', paid='{colPaid}'")
            
            filtered = filter_df(df_ext)
            dbg("after filter", filtered)
    
            filtered = add_matches_combined(filtered, new_col_name="Matches")
            dbg("after Matches", filtered)
    
            filtered = add_wide_matches_column(filtered, new_col_name="WideMatches", exclude_col="Matches")
            dbg("after Wide", filtered)



            c1, c2 = st.columns(2)
            c1.caption(f"External rows total: {len(df_ext)}")

            # --- Sidebar Filters (EXTERNAL) ‚Äî —Ç–µ –∂–µ, –Ω–æ —Å –¥—Ä—É–≥–∏–º–∏ key ---
            dff = filtered.copy()

            col_group      = _pick_col(dff, {"group","group title","group name","group id"}, fallback_idx=1)
            col_tutor      = _pick_col(dff, {"tutor","teacher","tutor name","teacher name"}, fallback_idx=4)
            col_tutor_id   = _pick_col(dff, {"tutor id","teacher id","id"}, fallback_idx=14)
            col_course     = _pick_col(dff, {"course"}, fallback_idx=5)
            col_group_age  = _pick_col(dff, {"group age","age"}, fallback_idx=6)
            col_local_time = _pick_col(dff, {"local time","localtime","time (local)"}, fallback_idx=8)
            col_module     = _pick_col(dff, {"module"}, fallback_idx=2)
            col_lesson_num = _pick_col(dff, {"lesson number","lesson","lesson_num"}, fallback_idx=13)
            col_capacity   = _pick_col(dff, {"capacity","cap"})
            col_paid       = _pick_col(dff, {"paid students","paid student","paid"})
            col_transfer1  = _pick_col(dff, {"students transferred 1 time","transferred 1 time"}, fallback_idx=11)
            col_paid_pct   = _pick_col(dff, {"paid %","paid percent","paid percentage","paid pct"})

            col_m_text  = "Matches"           if "Matches"           in dff.columns else None
            col_m_cnt   = "Matches_count"     if "Matches_count"     in dff.columns else None
            col_w_text  = "WideMatches"       if "WideMatches"       in dff.columns else None
            col_w_cnt   = "WideMatches_count" if "WideMatches_count" in dff.columns else None

            def _ms_options(df_, col):
                if not col or col not in df_.columns: return []
                return sorted(df_[col].dropna().astype(str).unique())

            def _apply_ms(df_, col, sel):
                if not col or not sel: return df_
                return df_[df_[col].astype(str).isin(sel)]

            with st.sidebar.expander("Filters (External)", expanded=True):
                dff = _apply_ms(dff, col_group,      st.multiselect("Group",      _ms_options(dff, col_group), key="ms_group_ext"))
                dff = _apply_ms(dff, col_tutor,      st.multiselect("Tutor",      _ms_options(dff, col_tutor), key="ms_tutor_ext"))
                dff = _apply_ms(dff, col_tutor_id,   st.multiselect("Tutor ID",   _ms_options(dff, col_tutor_id), key="ms_tid_ext"))
                dff = _apply_ms(dff, col_course,     st.multiselect("Course",     _ms_options(dff, col_course), key="ms_course_ext"))
                dff = _apply_ms(dff, col_group_age,  st.multiselect("Group age",  _ms_options(dff, col_group_age), key="ms_age_ext"))
                dff = _apply_ms(dff, col_local_time, st.multiselect("Local time", _ms_options(dff, col_local_time), key="ms_time_ext"))
                dff = _apply_ms(dff, col_module,     st.multiselect("Module",     _ms_options(dff, col_module), key="ms_module_ext"))

                dff = _apply_ms(dff, col_lesson_num, st.multiselect("Lesson number", _ms_options(dff, col_lesson_num), key="ms_lesson_ext"))
                dff = _apply_ms(dff, col_capacity,   st.multiselect("Capacity",      _ms_options(dff, col_capacity), key="ms_cap_ext"))
                dff = _apply_ms(dff, col_paid,       st.multiselect("Paid students", _ms_options(dff, col_paid), key="ms_paid_ext"))
                dff = _apply_ms(dff, col_paid_pct,   st.multiselect("Paid %",        _ms_options(dff, col_paid_pct), key="ms_paidpct_ext"))
                dff = _apply_ms(dff, col_transfer1,  st.multiselect("Students transferred 1 time", _ms_options(dff, col_transfer1), key="ms_tr1_ext"))

                if col_m_cnt:
                    min_m = st.number_input("Min Matches",      min_value=0, value=0, step=1, key="min_m_ext")
                    dff = dff[pd.to_numeric(dff[col_m_cnt], errors="coerce").fillna(0).astype(int) >= min_m]
                if col_w_cnt:
                    min_w = st.number_input("Min Wide matches", min_value=0, value=0, step=1, key="min_w_ext")
                    dff = dff[pd.to_numeric(dff[col_w_cnt], errors="coerce").fillna(0).astype(int) >= min_w]

                q = st.text_input("Search in matches text", key="q_ext")
                if q:
                    qrx = re.escape(q)
                    mask = pd.Series(False, index=dff.index)
                    for col in [col_m_text, col_w_text]:
                        if col:
                            mask |= dff[col].astype(str).str.contains(qrx, case=False, na=False)
                    dff = dff[mask]

                only_any = st.checkbox("Only rows with any matches", value=False, key="only_any_ext")
                if only_any:
                    cnt = pd.Series(0, index=dff.index)
                    for col in [col_m_cnt, col_w_cnt]:
                        if col:
                            cnt = cnt.add(pd.to_numeric(dff[col], errors="coerce").fillna(0).astype(int), fill_value=0)
                    dff = dff[cnt > 0]

            st.success(f"Filtered rows (External): {len(dff)}")

            cols_all = list(dff.columns)
            def col(idx):
                return cols_all[idx] if idx < len(cols_all) else None

            colA, colB, colC = col(0), col(1), col(2)
            colE, colF, colG = col(4), col(5), col(6)
            colI, colJ, colK = col(8), col(9), col(10)
            colL, colN, colO = col(11), col(13), col(14)

            rating_colname = _find_rating_col(dff)
            desired = [
                colA, colB, colE, colO, rating_colname,
                colF, colG, colI,
                _pick_col(dff, {"capacity","cap"}), _pick_col(dff, {"paid students","paid student","paid"}), "Free slots", "Paid %",
                colK, colC, colN, colL,
                "Matches_count", "Matches",
                "WideMatches_count", "WideMatches",
            ]
            display_cols = [c for c in desired if (c is not None and c in dff.columns)]
            seen = set()
            display_cols = [c for c in display_cols if not (c in seen or seen.add(c))]
            curated = dff.loc[:, display_cols].copy()
            curated = curated.loc[:, ~curated.columns.duplicated()]
            if rating_colname and rating_colname in curated.columns:
                curated.rename(columns={rating_colname: "Rating"}, inplace=True)

            def _to_na(v):
                if v is None or pd.isna(v): return pd.NA
                if isinstance(v, str):
                    s = (v.replace("\u00A0"," ").replace("\u200B","").replace("\u200C","").replace("\u200D","").replace("\uFEFF","").strip())
                    if s == "" or s.lower() in {"nan","none","null","na"}: return pd.NA
                    return s
                return v
            curated = curated.applymap(_to_na)

            count_cols = [c for c in ["Matches_count","WideMatches_count"] if c in curated.columns]
            text_cols  = [c for c in ["Matches","WideMatches"] if c in curated.columns]
            base_cols  = [c for c in curated.columns if c not in (count_cols + text_cols)]
            has_base   = curated[base_cols].notna().any(axis=1) if base_cols else False
            has_text   = curated[text_cols].notna().any(axis=1) if text_cols else False
            has_counts = (sum(pd.to_numeric(curated[c], errors="coerce").fillna(0).astype(int) for c in count_cols) > 0) if count_cols else False
            curated = curated[ has_base | has_text | has_counts ].reset_index(drop=True)

            ROW, HEADER, PAD = 34, 39, 8
            table_h = min(700, HEADER + ROW * max(1, len(curated)))

            cfg = {}
            for c in ["BO","Group","Tutor","Course","Matches","WideMatches"]:
                if c in curated.columns: cfg[c] = st.column_config.TextColumn(label=c, width="large")
            for c in ["Lesson number","Capacity","Paid students","Free slots","Paid %","Students transferred 1 time",
                      "Module","Group age","Local time","Matches_count","WideMatches_count"]:
                if c in curated.columns: cfg[c] = st.column_config.TextColumn(label=c, width="small")

            st.dataframe(curated, use_container_width=True, height=table_h, column_config=cfg)
            st.download_button("‚¨áÔ∏è Download CSV (external)", curated.to_csv(index=False).encode("utf-8"),
                               file_name="curated_external.csv", mime="text/csv")


    if st.button("Refresh"):
        load_sheet_df.clear()
        load_group_age_map.clear()
        load_rating_bp_map.clear()
        st.rerun()


if __name__ == "__main__":
    main()
